{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name(ind, num1):\n",
    "    a = num1 % 30 +1\n",
    "    b = num1 // 30 +1\n",
    "    return './../Data/train_db/%s_%02d%03d.txt' % (ind, b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cros(x1, x2):\n",
    "    x1['key'] = 1\n",
    "    x2['key'] = 1\n",
    "    df = pd.merge(x1, x2, on='key')\n",
    "    del df['key']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, id_list, example_count=270, batch_size=32):\n",
    "        'Initialization'\n",
    "        # id_list is list of person ids\n",
    "        self.id_list = id_list\n",
    "        # number of examples per person\n",
    "        self.example_count = example_count\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        num = index % len(self.id_list)\n",
    "        ind = self.id_list[num]\n",
    "        x1 = pd.read_csv(name(ind, 0), delimiter=' ', header=None).drop([0,1,402],axis=1)\n",
    "        l = []\n",
    "        for i in range(int(self.batch_size/2)):\n",
    "            name1 = ''\n",
    "            while not os.path.isfile(name1):\n",
    "                rand1 = random.randint(1,self.example_count)\n",
    "                name1 = name(ind,rand1)\n",
    "            x_same = pd.read_csv(name1 , delimiter=' ', header=None).drop([0,1,402],axis=1)\n",
    "            x_same['label'] = 1\n",
    "            l.append(x_same)\n",
    "            \n",
    "            rand2 = random.randint(0,self.example_count)\n",
    "            num2=-1\n",
    "            name2 = ''\n",
    "            while num2 == num or not os.path.isfile(name2):\n",
    "                rand3 = random.randint(0,len(self.id_list))\n",
    "                num2 = rand3 % len(self.id_list)\n",
    "                ind2 = self.id_list[num2]\n",
    "                name2 = name(ind2,rand2)\n",
    "            x_another = pd.read_csv(name2, delimiter=' ', header=None).drop([0,1,402],axis=1)\n",
    "            x_another['label'] = 0\n",
    "            l.append(x_another)\n",
    "        partners = pd.concat(l, axis=0) \n",
    "        \n",
    "        X = cros(x1, partners)  \n",
    "        y = X.pop('label')\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=DataGenerator(['0001', '0002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gen.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y.shape, np.sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejection(y_true, y_pred, b=0):\n",
    "    return np.sum((1 - np.round(y_pred+b)) * y_true)\n",
    "\n",
    "def acceptance(y_true, y_pred, b=0):\n",
    "    return np.sum((1 - y_true) *  np.round(y_pred+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(np.random.rand(10),columns=['pred'])\n",
    "x['label'] = pd.DataFrame(np.round(np.random.rand(10)))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rejection(x.label, x.pred), acceptance(x.label, x.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = rejection(x.label, x.pred)- acceptance(x.label, x.pred)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejection(x.label, x.pred, b=b), acceptance(x.label, x.pred, b=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "delta = x[x.pred * np.sign(diff) <.5*np.sign(diff)]\n",
    "\n",
    "delta['d'] = 0.5-delta.pred\n",
    "s = delta.sort_values('d')\n",
    "b = (s.iloc[int(diff)].d+s.iloc[int(diff)-1].d)/2\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta.sort_values('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def eer(y_true, y_pred):\n",
    "    rej = tf.reduce_sum((1 - tf.round(y_pred)) * y_true)\n",
    "    accept = tf.reduce_sum((1 - y_true) *  tf.round(y_pred))\n",
    "    diff = rej - accept\n",
    "    diffm = tf.abs(diff)\n",
    "    #delta = y_pred[y_pred * K.sign(diff) < 0.5*K.sign(diff)]\n",
    "    delta = tf.boolean_mask(y_pred, y_pred * K.sign(diff) <0.5*K.sign(diff))\n",
    "    ones = tf.ones(2)\n",
    "    d = tf.concat([ones, tf.abs(0.5-delta)], axis=0)\n",
    "\n",
    "    s1, _ = tf.nn.top_k(-1*d, tf.cast(diffm, dtype='int32')+1)\n",
    "    s11 = -1*s1\n",
    "    s2 = tf.concat([ones, s11], axis=0)\n",
    "    s = (s2[-1] + s2[-2]) /2\n",
    "    b = s * tf.sign(diff)\n",
    "    res = K.mean(K.equal(y_true, tf.round(y_pred+b)))\n",
    "    return res, b, s11, d, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_eer(y_true, y_pred):\n",
    "    rej = np.sum((1 - np.round(y_pred)) * y_true)\n",
    "    accept = np.sum((1 - y_true) *  np.round(y_pred))\n",
    "    print('rej=%s, acc=%s' %(rej,accept))\n",
    "    diff = rej - accept\n",
    "    diffm = np.abs(diff)\n",
    "    delta = y_pred[y_pred * np.sign(diff) <.5*np.sign(diff)]\n",
    "    print(delta)\n",
    "    if (np.size(delta) < 2):\n",
    "        return np.mean(np.equal(y_true, np.round(y_pred)))\n",
    "    d = np.abs(0.5-delta)\n",
    "    print(d)\n",
    "    s1 = np.sort(d)\n",
    "    print(s1)\n",
    "    b = (s1[int(diffm)]+s1[int(diffm)-1])/2 * np.sign(diff)\n",
    "    print('b=%s' % b)\n",
    "    res = np.mean(np.equal(y_true, np.round(y_pred+b)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "a, b, c, d, e = eer(x.label.values.astype('float32'), x.pred.values.astype('float32'))\n",
    "with tf.Session() as sess:\n",
    "  d1 = sess.run([a, b, c, d, e])\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_eer(x.label.values, x.pred.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "p = re.compile('/([0-9]+)')\n",
    "id_list = list({p.search(file).group(1) for file in glob.glob('./../Data/train_db/*')})\n",
    "len(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0.], dtype=float32), array([3], dtype=int32), array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.ones(2)\n",
    "b = tf.zeros(3)\n",
    "s =tf.tile(a, [12])\n",
    "s1 = tf.reshape(s, [12, -1])\n",
    "sh = tf.shape(b)\n",
    "b1, _ = tf.nn.top_k(b,2)\n",
    "c= tf.concat([a,b1], axis=0)\n",
    "with tf.Session() as sess:\n",
    "  d = sess.run([b1, sh, s1])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.single_generator import SingleGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s, ls = sg.__getitem__(4)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "s1, s2 = train_test_split(ls, test_size=0.3)\n",
    "len(s1), len(s2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52284"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "file_list = [file for file in glob.glob('./../Data/train_db/*')]\n",
    "\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47055, 5229)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_files, valid_files = train_test_split(file_list, test_size=0.1)\n",
    "len(train_files), len(valid_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from lib.single_generator import SingleGenerator\n",
    "sg = SingleGenerator(valid_files, id_list=id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, ls = sg.__getitem__(4)\n",
    "len(ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from lib.list_generator import ListGenerator\n",
    "lg = ListGenerator(file_list, id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, ls = lg.__getitem__(4)\n",
    "ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s[0]), len(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20/20 [==============================] - 21s 1s/step - loss: 0.7189 - acc: 0.5547 - val_loss: 0.9290 - val_acc: 0.4500\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization, Concatenate\n",
    "a1 = Input(shape=(400,))\n",
    "a2 = Input(shape=(400,))\n",
    "\n",
    "resh = Concatenate(axis=-1)([a1, a2])\n",
    "j = Dense(20)(resh)\n",
    "i = BatchNormalization()(j)\n",
    "k = Activation('relu')(i)\n",
    "l = Dense(1)(k)\n",
    "res = Activation('sigmoid')(l)\n",
    "compiled_model = Model(inputs=[a1, a2], outputs=[res])\n",
    "\n",
    "compiled_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "compiled_history = compiled_model.fit_generator(generator=lg,\n",
    "                    validation_data=lg,\n",
    "                    epochs=1, steps_per_epoch=20, validation_steps=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
